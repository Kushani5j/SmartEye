 <!-- FlatFy Theme - Andrea Galanti /-->
<!doctype html>
<!--[if lt IE 7]> <html class="no-js ie6 oldie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js ie7 oldie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js ie8 oldie" lang="en"> <![endif]-->
<!--[if IE 9]>    <html class="no-js ie9" lang="en"> <![endif]-->
<!--[if gt IE 9]><!--> <html> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="description" content="Flatfy Free Flat and Responsive HTML5 Template ">
    <meta name="author" content="">

    <title>Element</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link rel="shortcut icon" href="icon.ico">
 
    <!-- Custom Google Web Font -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic' rel='stylesheet' type='text/css'>
	<link href='http://fonts.googleapis.com/css?family=Arvo:400,700' rel='stylesheet' type='text/css'>
	
    <!-- Custom CSS-->
    <link href="css/general.css" rel="stylesheet">
	
	 <!-- Owl-Carousel -->
    <link href="css/custom.css" rel="stylesheet">
	<link href="css/owl.carousel.css" rel="stylesheet">
    <link href="css/owl.theme.css" rel="stylesheet">
	<link href="css/style.css" rel="stylesheet">
	<link href="css/animate.css" rel="stylesheet">
	
	<!-- Magnific Popup core CSS file -->
	<link rel="stylesheet" href="css/magnific-popup.css"> 
	
	<script src="js/modernizr-2.8.3.min.js"></script>  <!-- Modernizr /-->
	<!--[if IE 9]>
		<script src="js/PIE_IE9.js"></script>
	<![endif]-->
	<!--[if lt IE 9]>
		<script src="js/PIE_IE678.js"></script>
	<![endif]-->

	<!--[if lt IE 9]>
		<script src="js/html5shiv.js"></script>
	<![endif]-->

</head>

<body id="home">

	
	<!-- NavBar-->
	<nav class="navbar-default stuckMenu isStuck" style="position: relative; top: 0px;" role="navigation" >
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
                
				<a class="navbar-brand" href="index.html#whatis"><img src ="img/logo.png" style="height: 100px;margin-top: -35px;"></a>
			</div>

			<div class="collapse navbar-collapse navbar-right navbar-ex1-collapse">
				<ul class="nav navbar-nav">
					
					<li class="menuItem"><a href="index.html#whatis">Home</a></li>
					<li class="menuItem"><a href="index.html#domain">Domain</a></li>
					<li class="menuItem"><a href="index.html#documents">Documents</a></li>
					<li class="menuItem"><a href="index.html#presentations">Presentations</a></li>
					<li class="menuItem"><a href="index.html#milestones">Milestones</a></li>
					<li class="menuItem"><a href="index.html#achievements">Achievements</a></li>
                    <li class="menuItem"><a href="index.html#aboutsus">About Us</a></li>
					<li class="menuItem"><a href="index.html#contact">Contact Us</a></li>
				</ul>
			</div>
		   
		</div>
	</nav> 
	
	<!-- What is -->
	<div id="whatis" class="content-section-b" style="border-top: 0">
		<div class="container">

			<div class="col-md-6 col-md-offset-3 text-center wrap_title">
				<h2>Literature Survey</h2>
				
				
			</div>
			
			<div class="row">
			
				<div class="col-sm-12 wow fadeInDown text-center">
				  <img class="rotate" src="img/icon/LS.png" alt="Generic placeholder image" style="height:110px">
				  <p class="lead" align="justify">
						Assistive technology assists people with disabilities to achieve their ordinary life
						tasks and helps them in work, transportation, work and educational activities and it
						guides them to accomplish better independence and makes the life more comfortable.
						According to World Health Organization (WHO) official statistics, there are 285
						million visually impaired people (blind) in the world in which 39 millions of them
						are blind and 87% of them are from developing countries[1].
						Visually impaired people have a huge disadvantage as they are lacking details for
						bypassing objects, moving objects such as vehicles towards them, keeping a proper
						orientation and sudden changings of body vitals. The main objective when designing
						this type of assistive technology is to give some convenient information to visually
						impaired people during the mobility process such as walking.
						Mobility is the main problem encountered by visually impaired people. Over
						decades, they were using navigational tools such as guide dogs and white canes. The
						white cane is the most traditional mobility aid used to detect objects in the path of the
						blind. The white cane length depends on the height of the person. The guide dogs are
						trained to lead the blind around obstacles.
						<br>
						<br>
						<b>Identifying obstacles in user’s path including obstacles below ground level
						and obstacles above waist.</b>
						<br>
						<br>

Due to the huge development of modern technology, many kinds of navigational
tools are now available to aid the blinds. Some of these are Sonic Pathfinder, Mowat-
Sensor and Guide-Cane, but they have narrow directivity. However there are
different kind of devices which have wide directivity and they can search several
obstacles simultaneously. Those devices are based on producing beams of laser light
or ultrasonic sound.
<br>
In that kind of system, the tool receives reflected waves, and then produces a
vibration or ultrasonic sound in reply to nearby objects, but the market acceptance is
less as useful details gathered from the tools are not remarkably more than that from
the white cane and replies received from the tools are not much user friendly.
Therefore, the latest research efforts are being turned to come up with new
navigational system in which digital video camera is used as vision sensor. The tools
such as vOICe, SVETA and CASBLIP are used for the latest researches.
<br>

A developed stereo matching transforms images to figure out opaque discrepancy
image in SVETA. Right or left and low texture filter discrepancy check are brought
out to detach the noises and to point up the obstacles.
The image will be captured using a single camera mounted from a headgear and the
image will be scanned starting from left to right in voICe. The sound is created by
notifying the bottom part to the low frequency tones and the top of the image to the
high frequency tones. The sound loudness depends on the pixel brightness.
In CASBLIP, the obstacle is perceived from stereo vision and sensors. Furthermore,
orientation is figured out using GPS system. The system is fixed on Field
Programmable Gate Array (FPGA).
<br>
<br>
<b>Calculating the speed of the closest object in user’s path relative to the
pace that the user is travelling.</b>
	<br>
	<br>
Automatic identification of obstacle motion is one main capability of visually
impaired people for situation awareness and collision-free navigation in scenes.
Motion detection using a camera has been researched for years which utilizes
varies approaches like frame difference, background subtraction, and optical flow.
These approaches are not straight relevant to many solicitations that require motion
like mobile robots and unmanned aerial vehicles, etc. The main reason is the mobile
cameras normally introduce difficult and different background. Some of processes
have been announced to control motion detection using a moving camera.<br>
Object-level motion detection has two types of approaches. The first type is using a
deviation of the target obstacle’s radial optical flow field by that of the nearby
objects. It detects whether the moving direction and speed of the obstacle is
compatible with background radial types. Furthermore, the obstacle’s motion
deviates from the background radial type, as object is a moving object. An easy
baseline strategy is used to contrast the moving deviation for the decision making
while it is commonly vulnerable to colour, noise, and occlusion changes. Normally,
this kind of approach is efficient and simple but lacks effective and deep
representation of the moving deviation.<br>
The second kind of approach is using capable background model to approximate the
moving vectors of the differing backgrounds for each and every frame and detecting
the motion foreground areas using image difference or background subtraction
between successive video frames. It requests compound background model and
works properly when the background will not experience immediate changes. Hence,
the camera is moving actively, it will not be able to create proper estimation due to
the thorough background changes.
<br><br>
<b>Analysing user’s walking path and calculate user’s orientation relative to
their path and alert the user if they are deviating from the path (direction of the
deviation and the degree of deviation should be mentioned). Give a success alert
when user corrects his orientation.</b><br><br>
In the past few years, different type of work has been done in image processing,
robotics and speech recognition. Chang Jeong and Jin Park of the Korea University
have worked on an algorithm for real time lane detection for intelligent transport
system. They suggested a high performance and optimized Line Hough
Transform circuit technology for minimizing the logic and the number of cycle time.<br>
Department of Electronics & Telecommunication Technology Government
Engineering College, Raipur, India has done a research on Robot navigation using
image processing and isolated word recognition. First, they have captured video
frames and the captured frames were processed in MATLAB image processing
toolbox.<br><br>

<b>Tracking user vitals and identifying changes in vitals to generate possible
cause of vital change and notifying the relative of the user.</b><br><br>
We use data from a study by Listen to Your Heart: Stress Prediction Using
Consumer Heart Rate Sensors by David Liu, Mark Ulrich. They used an
automatic QRS wave annotation tool (WQRS) on the ECG data to identify
morphological features in the ECG, such as the R peak of each heartbeat. The RR
intervals (lengths of intervals between heartbeats) are then used to extract heart rate
variability (HRV) features. They have used tools available through the PhysioNet
WFDB package and HRV features that are commonly used for ECG analysis. The
time-domain features of HRV consist of the following characteristics of RR
intervals:<br>
	• NN/RR: The fraction of heartbeats that are considered “normal” heartbeat
	lengths<br>
• AVNN, SDNN, SDANN: Average and standard deviation of RR intervals<br>
• SDNNIDX: Mean of the standard deviations of RR intervals in all 5-minut
segments<br>
• RMSSD: RMS difference between adjacent RR intervals<br>
• PNN: Percentage of adjacent RR intervals that differ by more than 50ms<br>
Stress Detection by Measuring Heart Rate Variability research by Dipali H. Patil,
Garima Kumari, Pooja Daware, Vijayalaxmi Shinde, Akanksha Pran Raina
Department Of Information Technologyhas used HRV. There is a series of
measurements which consists of successive RR interval that varies of sinus variation
which provides information about automatic tone. Various factors influencing HRV
include age, gender, respiration and body position. HRV is generally performed on
the basis of 24-hour Holter recording or on a short range in between of 0.5 to 5 min
mainly focusing on electrocardiography field.<br>
As these systems have the qualities of portability, low cost, and above all simplicity
of controls, the visually impaired people can use them easily. For portability, this
ETA device has to be small and light weighted. The device should be controlled
easily and user friendly since the blind people are not able to see the display.
Furthermore, the device should be low-cost so that it can be affordable. Not only the
above requirements, the responding time and the reliability is the most important and
considerable fact in the navigational system like this. Considering all these
requirements, Smart Eye will come up with all those qualities using the latest
technologies.
                    
                    </p>

				  <!-- <p><a class="btn btn-embossed btn-primary view" role="button">View Details</a></p> -->
				</div><!-- /.col-lg-4 -->
				
				
			</div><!-- /.row -->
		</div>
	</div>
	
	<!-- Use it -->
    

  

    
	<!-- Screenshot -->
	
	
	
			
				
						<div class="morph-button wow pulse morph-button-inflow morph-button-inflow-1" style="visibility:hidden;">
							<button type="button " style="visibility: hidden;"><span>Subscribe to our Newsletter</span></button>
    </div>
					
				
			
	
	<!-- Credits -->
	
	<!-- Banner Download -->

	
	
	
    <footer>
      <div class="container" style="background-color:#34495e">
        <div class="row" >
          <div class="col-md-12" >
              <span style="text-align:center;margin-left:32%">2018 © Team Dynamic. ALL Rights Reserved - 18-025</span>
            </div>
        </div>
    
    </footer>

    <!-- JavaScript -->
    <script src="js/jquery-1.10.2.js"></script>
    <script src="js/bootstrap.js"></script>
	<script src="js/owl.carousel.js"></script>
	<script src="js/script.js"></script>
	<!-- StikyMenu -->
	<script src="js/stickUp.min.js"></script>
	<script type="text/javascript">
	  jQuery(function($) {
		$(document).ready( function() {
		  $('.navbar-default').stickUp();
		  
		});
	  });
	
	</script>
	<!-- Smoothscroll -->
	<script type="text/javascript" src="js/jquery.corner.js"></script> 
	<script src="js/wow.min.js"></script>
	<script>
	 new WOW().init();
	</script>
	<script src="js/classie.js"></script>
	<script src="js/uiMorphingButton_inflow.js"></script>
	<!-- Magnific Popup core JS file -->
	<script src="js/jquery.magnific-popup.js"></script> 
</body>

</html>
